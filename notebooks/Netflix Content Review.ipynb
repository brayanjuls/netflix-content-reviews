{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/brayanjules/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "import pyspark.sql.functions as fc\n",
    "from pyspark.sql.functions import column as col,udf\n",
    "import pyspark.sql.types as tp\n",
    "from datetime import datetime as dt\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.16:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11e262b50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    ".config(\"spark.jars.packages\",\"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.4\")\\\n",
    ".config(\"spark.hadoop.orc.overwrite.output.file\",\"true\")\\\n",
    ".getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load catalog data and get ride of malformed rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files(dataset=\"shivamb/netflix-shows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_catalog_path='/Users/brayanjules/Projects/personal/data engineer/datasets/raw_netflix_catalog'\n",
    "catalog = spark.read.csv(netflix_catalog_path,inferSchema=True, header=True,mode=\"DROPMALFORMED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catalog.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>81011096</td>\n",
       "      <td>Movie</td>\n",
       "      <td>최강전사 미니특공대 : 영웅의 탄생</td>\n",
       "      <td>Young Jun Lee</td>\n",
       "      <td>Um Sang-hyun, Yang Jeong-hwa, Jeon Tae-yeol, S...</td>\n",
       "      <td>None</td>\n",
       "      <td>September 1, 2018</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-Y7-FV</td>\n",
       "      <td>68 min</td>\n",
       "      <td>Children &amp; Family Movies</td>\n",
       "      <td>Miniforce, a special task force of elite range...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80226357</td>\n",
       "      <td>Movie</td>\n",
       "      <td>반드시 잡는다</td>\n",
       "      <td>Hong-seon Kim</td>\n",
       "      <td>Baek Yoon-sik</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>February 28, 2018</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>110 min</td>\n",
       "      <td>Dramas, International Movies, Thrillers</td>\n",
       "      <td>After people in his town start turning up dead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>80226338</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>마녀사냥</td>\n",
       "      <td>None</td>\n",
       "      <td>Si-kyung Sung, Se-yoon Yoo, Dong-yup Shin, Ji-...</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>February 19, 2018</td>\n",
       "      <td>2015</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>International TV Shows, Korean TV Shows, Stand...</td>\n",
       "      <td>Four Korean celebrity men and guest stars of b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_id     type                title       director  \\\n",
       "0  81011096    Movie  최강전사 미니특공대 : 영웅의 탄생  Young Jun Lee   \n",
       "1  80226357    Movie              반드시 잡는다  Hong-seon Kim   \n",
       "2  80226338  TV Show                 마녀사냥           None   \n",
       "\n",
       "                                                cast      country  \\\n",
       "0  Um Sang-hyun, Yang Jeong-hwa, Jeon Tae-yeol, S...         None   \n",
       "1                                      Baek Yoon-sik  South Korea   \n",
       "2  Si-kyung Sung, Se-yoon Yoo, Dong-yup Shin, Ji-...  South Korea   \n",
       "\n",
       "          date_added release_year    rating  duration  \\\n",
       "0  September 1, 2018         2018  TV-Y7-FV    68 min   \n",
       "1  February 28, 2018         2017     TV-MA   110 min   \n",
       "2  February 19, 2018         2015     TV-MA  1 Season   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                           Children & Family Movies   \n",
       "1            Dramas, International Movies, Thrillers   \n",
       "2  International TV Shows, Korean TV Shows, Stand...   \n",
       "\n",
       "                                         description  \n",
       "0  Miniforce, a special task force of elite range...  \n",
       "1  After people in his town start turning up dead...  \n",
       "2  Four Korean celebrity men and guest stars of b...  "
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog_ordered=catalog.orderBy(fc.desc('title'))\n",
    "catalog_ordered.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Netflix Catalog Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplication of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Oh My Ghost</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tunnel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The Silence</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Limitless</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title  count\n",
       "0  Oh My Ghost      3\n",
       "1       Tunnel      3\n",
       "2  The Silence      3\n",
       "3         Love      3\n",
       "4    Limitless      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicatedContent=catalog.groupBy(['title']).count().orderBy(fc.desc('count'))\n",
    "duplicatedContent.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80244078</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Silence</td>\n",
       "      <td>Gajendra Ahire</td>\n",
       "      <td>Raghuvir Yadav, Nagraj Manjule, Anjali Patil, ...</td>\n",
       "      <td>India</td>\n",
       "      <td>March 1, 2018</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>On a train in Mumbai, 20-something Chini witne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80238292</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Silence</td>\n",
       "      <td>Gajendra Ahire</td>\n",
       "      <td>Raghuvir Yadav, Nagraj Manjule, Anjali Patil, ...</td>\n",
       "      <td>India</td>\n",
       "      <td>March 1, 2018</td>\n",
       "      <td>2015</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>91 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After encountering a scene of sexual violence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>81021447</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Silence</td>\n",
       "      <td>John R. Leonetti</td>\n",
       "      <td>Stanley Tucci, Kiernan Shipka, Miranda Otto, K...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>April 10, 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>91 min</td>\n",
       "      <td>Horror Movies, Thrillers</td>\n",
       "      <td>With the world under attack by deadly creature...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_id   type        title          director  \\\n",
       "0  80244078  Movie  The Silence    Gajendra Ahire   \n",
       "1  80238292  Movie  The Silence    Gajendra Ahire   \n",
       "2  81021447  Movie  The Silence  John R. Leonetti   \n",
       "\n",
       "                                                cast  country      date_added  \\\n",
       "0  Raghuvir Yadav, Nagraj Manjule, Anjali Patil, ...    India   March 1, 2018   \n",
       "1  Raghuvir Yadav, Nagraj Manjule, Anjali Patil, ...    India   March 1, 2018   \n",
       "2  Stanley Tucci, Kiernan Shipka, Miranda Otto, K...  Germany  April 10, 2019   \n",
       "\n",
       "  release_year rating duration                     listed_in  \\\n",
       "0         2017  TV-MA   90 min  Dramas, International Movies   \n",
       "1         2015  TV-MA   91 min  Dramas, International Movies   \n",
       "2         2019  TV-14   91 min      Horror Movies, Thrillers   \n",
       "\n",
       "                                         description  \n",
       "0  On a train in Mumbai, 20-something Chini witne...  \n",
       "1  After encountering a scene of sexual violence,...  \n",
       "2  With the world under attack by deadly creature...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.where(catalog.title=='The Silence').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>81021447</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Silence</td>\n",
       "      <td>John R. Leonetti</td>\n",
       "      <td>Stanley Tucci, Kiernan Shipka, Miranda Otto, K...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>April 10, 2019</td>\n",
       "      <td>2019</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>91 min</td>\n",
       "      <td>Horror Movies, Thrillers</td>\n",
       "      <td>With the world under attack by deadly creature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80244078</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Silence</td>\n",
       "      <td>Gajendra Ahire</td>\n",
       "      <td>Raghuvir Yadav, Nagraj Manjule, Anjali Patil, ...</td>\n",
       "      <td>India</td>\n",
       "      <td>March 1, 2018</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>On a train in Mumbai, 20-something Chini witne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_id   type        title          director  \\\n",
       "0  81021447  Movie  The Silence  John R. Leonetti   \n",
       "1  80244078  Movie  The Silence    Gajendra Ahire   \n",
       "\n",
       "                                                cast  country      date_added  \\\n",
       "0  Stanley Tucci, Kiernan Shipka, Miranda Otto, K...  Germany  April 10, 2019   \n",
       "1  Raghuvir Yadav, Nagraj Manjule, Anjali Patil, ...    India   March 1, 2018   \n",
       "\n",
       "  release_year rating duration                     listed_in  \\\n",
       "0         2019  TV-14   91 min      Horror Movies, Thrillers   \n",
       "1         2017  TV-MA   90 min  Dramas, International Movies   \n",
       "\n",
       "                                         description  \n",
       "0  With the world under attack by deadly creature...  \n",
       "1  On a train in Mumbai, 20-something Chini witne...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.where(catalog.title=='The Silence').dropDuplicates(['title','director']).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicated rows( those are the one that have the same title and director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>You're My Boss</td>\n",
       "      <td>Antoinette Jadaone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>You're Everything To Me</td>\n",
       "      <td>Tolga Örnek</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>You Get Me</td>\n",
       "      <td>Brent Bonacorso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title            director  count\n",
       "0           You're My Boss  Antoinette Jadaone      1\n",
       "1  You're Everything To Me         Tolga Örnek      1\n",
       "2               You Get Me     Brent Bonacorso      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_duplicated_content=catalog.dropDuplicates(['title','director']).orderBy(fc.desc('title'))\n",
    "non_duplicated_content.groupBy(['title','director']).count().orderBy(fc.desc('count')).limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand if there is movies without description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [show_id, type, title, director, cast, country, date_added, release_year, rating, duration, listed_in, description]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_valid_content=catalog.where((catalog.title).isNotNull() & (catalog.description).isNull())\n",
    "no_valid_content.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows without title or director."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify if there are rows without title or director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>William Wyler</td>\n",
       "      <td>1944</td>\n",
       "      <td>March 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\"Behind \"\"The Cove\"\": The Quiet Japanese Speak...</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Japan, United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"Escape from the \"\"Liberty\"\" Cinema\"</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Janusz Gajos, Zbigniew Zamachowski, Teresa Mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\"Gabriel \"\"Fluffy\"\" Iglesias: One Show Fits All\"</td>\n",
       "      <td>Movie</td>\n",
       "      <td>None</td>\n",
       "      <td>Gabriel Iglesias</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           type  \\\n",
       "0                                               None  William Wyler   \n",
       "1                                               None           None   \n",
       "2  \"Behind \"\"The Cove\"\": The Quiet Japanese Speak...          Movie   \n",
       "3               \"Escape from the \"\"Liberty\"\" Cinema\"          Movie   \n",
       "4   \"Gabriel \"\"Fluffy\"\" Iglesias: One Show Fits All\"          Movie   \n",
       "\n",
       "                country                                               cast  \n",
       "0                  1944                                     March 31, 2017  \n",
       "1                  None                                               None  \n",
       "2  Japan, United States                                               None  \n",
       "3                Poland  Janusz Gajos, Zbigniew Zamachowski, Teresa Mar...  \n",
       "4                  None                                   Gabriel Iglesias  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_duplicated_content.select('title','type','country','cast').orderBy(fc.asc('title')).limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80226338</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>마녀사냥</td>\n",
       "      <td>None</td>\n",
       "      <td>Si-kyung Sung, Se-yoon Yoo, Dong-yup Shin, Ji-...</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>February 19, 2018</td>\n",
       "      <td>2015</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>International TV Shows, Korean TV Shows, Stand...</td>\n",
       "      <td>Four Korean celebrity men and guest stars of b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80136789</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>海的儿子</td>\n",
       "      <td>None</td>\n",
       "      <td>Li Nanxing, Christopher Lee, Jesseca Liu, Appl...</td>\n",
       "      <td>None</td>\n",
       "      <td>April 27, 2018</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-PG</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>International TV Shows, TV Dramas</td>\n",
       "      <td>Two brothers start a new life in Singapore, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>80990464</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>忍者ハットリくん</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Japan</td>\n",
       "      <td>December 23, 2018</td>\n",
       "      <td>2012</td>\n",
       "      <td>TV-Y7</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>Anime Series, Kids' TV</td>\n",
       "      <td>Hailing from the mountains of Iga, Kanzo Hatto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_id     type     title director  \\\n",
       "0  80226338  TV Show      마녀사냥     None   \n",
       "1  80136789  TV Show      海的儿子     None   \n",
       "2  80990464  TV Show  忍者ハットリくん     None   \n",
       "\n",
       "                                                cast      country  \\\n",
       "0  Si-kyung Sung, Se-yoon Yoo, Dong-yup Shin, Ji-...  South Korea   \n",
       "1  Li Nanxing, Christopher Lee, Jesseca Liu, Appl...         None   \n",
       "2                                               None        Japan   \n",
       "\n",
       "           date_added release_year rating   duration  \\\n",
       "0   February 19, 2018         2015  TV-MA   1 Season   \n",
       "1      April 27, 2018         2016  TV-PG   1 Season   \n",
       "2   December 23, 2018         2012  TV-Y7  2 Seasons   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, Korean TV Shows, Stand...   \n",
       "1                  International TV Shows, TV Dramas   \n",
       "2                             Anime Series, Kids' TV   \n",
       "\n",
       "                                         description  \n",
       "0  Four Korean celebrity men and guest stars of b...  \n",
       "1  Two brothers start a new life in Singapore, wh...  \n",
       "2  Hailing from the mountains of Iga, Kanzo Hatto...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_duplicated_content \\\n",
    ".where((non_duplicated_content.title.isNull()) | (non_duplicated_content.director.isNull())) \\\n",
    ".limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80132127</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Behind The Cove: The Quiet Japanese Speak Out</td>\n",
       "      <td>Keiko Yagi</td>\n",
       "      <td>None</td>\n",
       "      <td>Japan, United States</td>\n",
       "      <td>August 25, 2017</td>\n",
       "      <td>2015</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>105 min</td>\n",
       "      <td>Documentaries, International Movies</td>\n",
       "      <td>After a documentary about the Japanese whaling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>81168345</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Escape from the Liberty Cinema</td>\n",
       "      <td>Wojciech Marczewski</td>\n",
       "      <td>Janusz Gajos, Zbigniew Zamachowski, Teresa Mar...</td>\n",
       "      <td>Poland</td>\n",
       "      <td>October 1, 2019</td>\n",
       "      <td>1990</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>88 min</td>\n",
       "      <td>Comedies, Dramas, Independent Movies</td>\n",
       "      <td>Artistic rebellion ignites at the movies when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>81087095</td>\n",
       "      <td>Movie</td>\n",
       "      <td>#Roxy</td>\n",
       "      <td>Michael Kennedy</td>\n",
       "      <td>Jake Short, Sarah Fisher, Booboo Stewart, Dann...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>April 10, 2019</td>\n",
       "      <td>2018</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>105 min</td>\n",
       "      <td>Comedies, Romantic Movies</td>\n",
       "      <td>A teenage hacker with a huge nose helps a cool...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_id   type                                          title  \\\n",
       "0  80132127  Movie  Behind The Cove: The Quiet Japanese Speak Out   \n",
       "1  81168345  Movie                 Escape from the Liberty Cinema   \n",
       "2  81087095  Movie                                          #Roxy   \n",
       "\n",
       "              director                                               cast  \\\n",
       "0           Keiko Yagi                                               None   \n",
       "1  Wojciech Marczewski  Janusz Gajos, Zbigniew Zamachowski, Teresa Mar...   \n",
       "2      Michael Kennedy  Jake Short, Sarah Fisher, Booboo Stewart, Dann...   \n",
       "\n",
       "                country       date_added release_year rating duration  \\\n",
       "0  Japan, United States  August 25, 2017         2015  TV-14  105 min   \n",
       "1                Poland  October 1, 2019         1990  TV-MA   88 min   \n",
       "2                Canada   April 10, 2019         2018  TV-14  105 min   \n",
       "\n",
       "                              listed_in  \\\n",
       "0   Documentaries, International Movies   \n",
       "1  Comedies, Dramas, Independent Movies   \n",
       "2             Comedies, Romantic Movies   \n",
       "\n",
       "                                         description  \n",
       "0  After a documentary about the Japanese whaling...  \n",
       "1  Artistic rebellion ignites at the movies when ...  \n",
       "2  A teenage hacker with a huge nose helps a cool...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_with_title=non_duplicated_content.dropna('any',subset=['title','director']).orderBy(fc.asc('title'))\n",
    "content_with_title=content_with_title.withColumn('title',fc.translate('title','\"',''))\n",
    "content_with_title.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix of column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_with_title=content_with_title.withColumn('show_id',col('show_id').cast(tp.LongType()))\n",
    "content_with_title=content_with_title.withColumn('release_year',col('release_year').cast(tp.IntegerType()))\n",
    "content_with_title=content_with_title.withColumn('date_added',fc.to_date('date_added','MMMMM dd, yyyy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Raúl Campos, Jan Suter</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Marcus Raboy</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Jay Karas</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 director  count\n",
       "0  Raúl Campos, Jan Suter     18\n",
       "1            Marcus Raboy     14\n",
       "2               Jay Karas     13"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topDirector=content_with_title.dropna('any',subset=['director']).where((catalog.type=='Movie')).groupBy('director').count().orderBy(fc.desc('count'))\n",
    "topDirector.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: long (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_with_title.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6172"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_with_title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_with_title.write.parquet('/Users/brayanjules/Projects/personal/data engineer/datasets/netflix_catalog/catalog.parquet','overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Netflix comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import os\n",
    "import pandas as pd\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brayanjules/Projects/personal/data engineer/nanodegre/capstone-project/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='k6twSlTNOdnGjQ',client_secret='NrQ-rdSKMOJM17yj3hO4apbmTis'\n",
    "                     ,\n",
    "                     user_agent='academic_comments_understanding:v1 by /u/zekeja') ## Use the praw.init when possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SubReddit Search by content ( netflix,NetflixBestOf,bestofnetflix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "redditSchema=tp.StructType([tp.StructField('show_title',tp.StringType(),True),\n",
    "                            tp.StructField('show_director',tp.StringType(),True),\n",
    "               tp.StructField('submission_id',tp.StringType(),True),\n",
    "               tp.StructField('source',tp.StringType(),True),\n",
    "               tp.StructField('title',tp.StringType(),True),\n",
    "               tp.StructField('description',tp.StringType(),True),\n",
    "               tp.StructField('created_utc',tp.TimestampType(),True),\n",
    "               tp.StructField('author',tp.StringType(),True),\n",
    "               tp.StructField('score',tp.IntegerType(),True),\n",
    "               tp.StructField('spoiler',tp.BooleanType(),True),\n",
    "               tp.StructField('is_original_content',tp.BooleanType(),True),\n",
    "               tp.StructField('distinguished',tp.StringType(),True),\n",
    "               tp.StructField('link',tp.StringType(),True),             \n",
    "               tp.StructField('comments',tp.ArrayType(tp.StructType([\n",
    "                   tp.StructField('comment_id',tp.StringType(),True),\n",
    "                   tp.StructField('body',tp.StringType(),True),\n",
    "                   tp.StructField('created_utc',tp.TimestampType(),True),\n",
    "                   tp.StructField('score',tp.IntegerType(),True),\n",
    "                   tp.StructField('parent_id',tp.StringType(),True),\n",
    "                   tp.StructField('submission_id',tp.StringType(),True)]\n",
    "               )),True)\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Generate 1000.0000 of comments for testing propouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import datetime as dat\n",
    "def randomString(stringLength=8):\n",
    "    letters = string.ascii_lowercase\n",
    "    return ''.join(random.choice(letters) for i in range(stringLength))\n",
    "\n",
    "def random_date(start, end):\n",
    "    \"\"\"\n",
    "    This function will return a random datetime between two datetime\n",
    "    objects.\n",
    "    \"\"\"\n",
    "    delta = end - start\n",
    "    int_delta = (delta.days * 24 * 60 * 60) + delta.seconds\n",
    "    random_second = random.randrange(int_delta)\n",
    "    return start + dat.timedelta(seconds=random_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_rows=[]\n",
    "index = 1\n",
    "for content in content_with_title.collect():\n",
    "    title_split=content.title.split(\":\",1)\n",
    "    content_title=title_split[0]\n",
    "    row_comments = []\n",
    "    cur_date = dat.datetime.now()\n",
    "    score = random.randint(0,100)\n",
    "    for source in ['netflix','tvshows']:\n",
    "        for index in range(0,250):\n",
    "            comment = randomString(random.randint(8,50))\n",
    "\n",
    "            created_date = random_date(cur_date - dat.timedelta(days=120),cur_date)\n",
    "            row_comments.append((str(index),comment,created_date,score,\n",
    "                                       'default_parent','default_link')) \n",
    "        current_sm=(content.title,content.director,index,source,content.title,'selftext',\n",
    "                    cur_date,'default_author',\n",
    "                      score,False,False,'','',row_comments)\n",
    "        content_rows.append(current_sm) \n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_rows=[]\n",
    "for content in content_with_title.limit(20).collect():\n",
    "    title_split=content.title.split(\":\",1)\n",
    "    content_title=title_split[0]\n",
    "    subreddit=reddit.subreddit('netflix')\n",
    "    for sm in subreddit.search('\"'+content_title+'\"',sort='new'):\n",
    "        sm.comments.replace_more(limit=None)\n",
    "        #print(sm.title)\n",
    "        row_comments = []\n",
    "        for comment in sm.comments.list():\n",
    "            row_comments.append((comment.id,comment.body,dt.fromtimestamp(float(comment.created_utc)),comment.score,\n",
    "                                       comment.parent_id,comment.link_id)) \n",
    "        current_sm=(content.title,content.director,sm.id,subreddit.display_name,sm.title,sm.selftext,\n",
    "                    dt.fromtimestamp(float(sm.created_utc)),sm.author.name,\n",
    "                      sm.score,sm.spoiler,sm.is_original_content,sm.distinguished,sm.permalink,row_comments)\n",
    "        content_rows.append(current_sm)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_title: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- spoiler: boolean (nullable = true)\n",
      " |-- is_original_content: boolean (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- comments: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- comment_id: string (nullable = true)\n",
      " |    |    |-- body: string (nullable = true)\n",
      " |    |    |-- created_utc: timestamp (nullable = true)\n",
      " |    |    |-- score: integer (nullable = true)\n",
      " |    |    |-- parent_id: string (nullable = true)\n",
      " |    |    |-- submission_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdt_netflix_content=spark.createDataFrame(content_rows,redditSchema)\n",
    "rdt_netflix_content.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_title</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>link</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>최강전사 미니특공대 : 영웅의 탄생</td>\n",
       "      <td>249</td>\n",
       "      <td>tvshows</td>\n",
       "      <td>최강전사 미니특공대 : 영웅의 탄생</td>\n",
       "      <td>selftext</td>\n",
       "      <td>2020-05-02 19:38:06.516381</td>\n",
       "      <td>default_author</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[(0, vmlmxgfynljprvejsncqbmcyetzqghckhgwexb, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>최강전사 미니특공대 : 영웅의 탄생</td>\n",
       "      <td>249</td>\n",
       "      <td>netflix</td>\n",
       "      <td>최강전사 미니특공대 : 영웅의 탄생</td>\n",
       "      <td>selftext</td>\n",
       "      <td>2020-05-02 19:38:06.516381</td>\n",
       "      <td>default_author</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[(0, vmlmxgfynljprvejsncqbmcyetzqghckhgwexb, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>반드시 잡는다</td>\n",
       "      <td>249</td>\n",
       "      <td>netflix</td>\n",
       "      <td>반드시 잡는다</td>\n",
       "      <td>selftext</td>\n",
       "      <td>2020-05-02 19:38:06.498860</td>\n",
       "      <td>default_author</td>\n",
       "      <td>97</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[(0, oegpqhqeywpruksxlhg, 2020-01-23 17:18:56....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            show_title submission_id   source                title  \\\n",
       "0  최강전사 미니특공대 : 영웅의 탄생           249  tvshows  최강전사 미니특공대 : 영웅의 탄생   \n",
       "1  최강전사 미니특공대 : 영웅의 탄생           249  netflix  최강전사 미니특공대 : 영웅의 탄생   \n",
       "2              반드시 잡는다           249  netflix              반드시 잡는다   \n",
       "\n",
       "  description                created_utc          author  score  spoiler  \\\n",
       "0    selftext 2020-05-02 19:38:06.516381  default_author     98    False   \n",
       "1    selftext 2020-05-02 19:38:06.516381  default_author     98    False   \n",
       "2    selftext 2020-05-02 19:38:06.498860  default_author     97    False   \n",
       "\n",
       "   is_original_content distinguished link  \\\n",
       "0                False                      \n",
       "1                False                      \n",
       "2                False                      \n",
       "\n",
       "                                            comments  \n",
       "0  [(0, vmlmxgfynljprvejsncqbmcyetzqghckhgwexb, 2...  \n",
       "1  [(0, vmlmxgfynljprvejsncqbmcyetzqghckhgwexb, 2...  \n",
       "2  [(0, oegpqhqeywpruksxlhg, 2020-01-23 17:18:56....  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdt_netflix_content.orderBy(fc.desc('created_utc')).limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_title</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>link</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Behind The Cove: The Quiet Japanese Speak Out</td>\n",
       "      <td>98y3ld</td>\n",
       "      <td>netflix</td>\n",
       "      <td>[UK] Netflix no longer has The Cove, the Oscar...</td>\n",
       "      <td>I appreciate having both sides of the argument...</td>\n",
       "      <td>2018-08-20 19:22:31</td>\n",
       "      <td>lewis_pritchard</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/98y3ld/uk_netflix_no_longe...</td>\n",
       "      <td>[(e4jp9zf, It's highly unlikely they know the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>#Roxy</td>\n",
       "      <td>g5uizp</td>\n",
       "      <td>netflix</td>\n",
       "      <td>Reciving Error M7111-5059 but I don't use any ...</td>\n",
       "      <td>Just today I have been unable to view any con...</td>\n",
       "      <td>2020-04-22 00:20:45</td>\n",
       "      <td>Atromix_</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/g5uizp/reciving_error_m711...</td>\n",
       "      <td>[(fo5muf4, Your ISP is probably using a shared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#Selfie</td>\n",
       "      <td>e8v216</td>\n",
       "      <td>netflix</td>\n",
       "      <td>Weird shirtless gym selfie on Netflix Twitter ...</td>\n",
       "      <td>[https://twitter.com/netflix/status/120445343...</td>\n",
       "      <td>2019-12-10 16:07:43</td>\n",
       "      <td>OrganicCorndawg</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/e8v216/weird_shirtless_gym...</td>\n",
       "      <td>[(faeoqgb, This response seems to explain it:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#Selfie</td>\n",
       "      <td>99vbkh</td>\n",
       "      <td>netflix</td>\n",
       "      <td>Selfie From Hell Movie: Ending Explained + Wha...</td>\n",
       "      <td></td>\n",
       "      <td>2018-08-24 04:14:30</td>\n",
       "      <td>PaulTweddle</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/99vbkh/selfie_from_hell_mo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>#realityhigh</td>\n",
       "      <td>8z4t4l</td>\n",
       "      <td>netflix</td>\n",
       "      <td>what the FUCK</td>\n",
       "      <td>was at a party right now (we all bet on croati...</td>\n",
       "      <td>2018-07-15 16:36:44</td>\n",
       "      <td>dickensian_nightmare</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/8z4t4l/what_the_fuck/</td>\n",
       "      <td>[(e2g8bs1, I’ll Give you an upvote because of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      show_title submission_id   source  \\\n",
       "0  Behind The Cove: The Quiet Japanese Speak Out        98y3ld  netflix   \n",
       "1                                          #Roxy        g5uizp  netflix   \n",
       "2                                        #Selfie        e8v216  netflix   \n",
       "3                                        #Selfie        99vbkh  netflix   \n",
       "4                                   #realityhigh        8z4t4l  netflix   \n",
       "\n",
       "                                               title  \\\n",
       "0  [UK] Netflix no longer has The Cove, the Oscar...   \n",
       "1  Reciving Error M7111-5059 but I don't use any ...   \n",
       "2  Weird shirtless gym selfie on Netflix Twitter ...   \n",
       "3  Selfie From Hell Movie: Ending Explained + Wha...   \n",
       "4                                      what the FUCK   \n",
       "\n",
       "                                         description         created_utc  \\\n",
       "0  I appreciate having both sides of the argument... 2018-08-20 19:22:31   \n",
       "1   Just today I have been unable to view any con... 2020-04-22 00:20:45   \n",
       "2   [https://twitter.com/netflix/status/120445343... 2019-12-10 16:07:43   \n",
       "3                                                    2018-08-24 04:14:30   \n",
       "4  was at a party right now (we all bet on croati... 2018-07-15 16:36:44   \n",
       "\n",
       "                 author  score  spoiler  is_original_content distinguished  \\\n",
       "0       lewis_pritchard    141    False                False          None   \n",
       "1              Atromix_      2    False                False          None   \n",
       "2       OrganicCorndawg      1    False                False          None   \n",
       "3           PaulTweddle      5    False                False          None   \n",
       "4  dickensian_nightmare      0    False                False          None   \n",
       "\n",
       "                                                link  \\\n",
       "0  /r/netflix/comments/98y3ld/uk_netflix_no_longe...   \n",
       "1  /r/netflix/comments/g5uizp/reciving_error_m711...   \n",
       "2  /r/netflix/comments/e8v216/weird_shirtless_gym...   \n",
       "3  /r/netflix/comments/99vbkh/selfie_from_hell_mo...   \n",
       "4          /r/netflix/comments/8z4t4l/what_the_fuck/   \n",
       "\n",
       "                                            comments  \n",
       "0  [(e4jp9zf, It's highly unlikely they know the ...  \n",
       "1  [(fo5muf4, Your ISP is probably using a shared...  \n",
       "2  [(faeoqgb, This response seems to explain it:\\...  \n",
       "3                                                 []  \n",
       "4  [(e2g8bs1, I’ll Give you an upvote because of ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdt_netflix_content.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, qty]\n",
       "Index: []"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_with_title.select('title').groupBy('title') \\\n",
    ".agg(fc.count('title').alias('qty')).filter(fc.col('qty')>1).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_title</th>\n",
       "      <th>qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [show_title, qty]\n",
       "Index: []"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdt_netflix_content.select('show_title').groupBy('show_title') \\\n",
    ".agg(fc.count('show_title').alias('qty')).filter(fc.col('qty')>1).orderBy(fc.desc('qty')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rdt_netflix_content.write.parquet(path=\"/Users/brayanjules/Projects/personal/data engineer/datasets/reddit_netflix/comments.parquet\",mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_test=content_with_title.limit(5).rdd.flatMap(lambda x:getRedditComments(reddit,x,'netflix',redditSchema))\n",
    "final_result=spark.createDataFrame(result_test,redditSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def test_x(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>submission_id</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>link</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80132127</td>\n",
       "      <td>98y3ld</td>\n",
       "      <td>netflix</td>\n",
       "      <td>[UK] Netflix no longer has The Cove, the Oscar...</td>\n",
       "      <td>I appreciate having both sides of the argument...</td>\n",
       "      <td>2018-08-20 19:22:31</td>\n",
       "      <td>lewis_pritchard</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/98y3ld/uk_netflix_no_longe...</td>\n",
       "      <td>[(e4jp9zf, It's highly unlikely they know the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>81087095</td>\n",
       "      <td>g5uizp</td>\n",
       "      <td>netflix</td>\n",
       "      <td>Reciving Error M7111-5059 but I don't use any ...</td>\n",
       "      <td>Just today I have been unable to view any con...</td>\n",
       "      <td>2020-04-22 00:20:45</td>\n",
       "      <td>Atromix_</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/g5uizp/reciving_error_m711...</td>\n",
       "      <td>[(fo5muf4, Your ISP is probably using a shared...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>81092768</td>\n",
       "      <td>99vbkh</td>\n",
       "      <td>netflix</td>\n",
       "      <td>Selfie From Hell Movie: Ending Explained + Wha...</td>\n",
       "      <td></td>\n",
       "      <td>2018-08-24 04:14:30</td>\n",
       "      <td>PaulTweddle</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/99vbkh/selfie_from_hell_mo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>81092768</td>\n",
       "      <td>e8v216</td>\n",
       "      <td>netflix</td>\n",
       "      <td>Weird shirtless gym selfie on Netflix Twitter ...</td>\n",
       "      <td>[https://twitter.com/netflix/status/120445343...</td>\n",
       "      <td>2019-12-10 16:07:43</td>\n",
       "      <td>OrganicCorndawg</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>/r/netflix/comments/e8v216/weird_shirtless_gym...</td>\n",
       "      <td>[(faeoqgb, This response seems to explain it:\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    show_id submission_id   source  \\\n",
       "0  80132127        98y3ld  netflix   \n",
       "1  81087095        g5uizp  netflix   \n",
       "2  81092768        99vbkh  netflix   \n",
       "3  81092768        e8v216  netflix   \n",
       "\n",
       "                                               title  \\\n",
       "0  [UK] Netflix no longer has The Cove, the Oscar...   \n",
       "1  Reciving Error M7111-5059 but I don't use any ...   \n",
       "2  Selfie From Hell Movie: Ending Explained + Wha...   \n",
       "3  Weird shirtless gym selfie on Netflix Twitter ...   \n",
       "\n",
       "                                         description         created_utc  \\\n",
       "0  I appreciate having both sides of the argument... 2018-08-20 19:22:31   \n",
       "1   Just today I have been unable to view any con... 2020-04-22 00:20:45   \n",
       "2                                                    2018-08-24 04:14:30   \n",
       "3   [https://twitter.com/netflix/status/120445343... 2019-12-10 16:07:43   \n",
       "\n",
       "            author  score  spoiler  is_original_content distinguished  \\\n",
       "0  lewis_pritchard    141    False                False          None   \n",
       "1         Atromix_      2    False                False          None   \n",
       "2      PaulTweddle      4    False                False          None   \n",
       "3  OrganicCorndawg      1    False                False          None   \n",
       "\n",
       "                                                link  \\\n",
       "0  /r/netflix/comments/98y3ld/uk_netflix_no_longe...   \n",
       "1  /r/netflix/comments/g5uizp/reciving_error_m711...   \n",
       "2  /r/netflix/comments/99vbkh/selfie_from_hell_mo...   \n",
       "3  /r/netflix/comments/e8v216/weird_shirtless_gym...   \n",
       "\n",
       "                                            comments  \n",
       "0  [(e4jp9zf, It's highly unlikely they know the ...  \n",
       "1  [(fo5muf4, Your ISP is probably using a shared...  \n",
       "2                                                 []  \n",
       "3  [(faeoqgb, This response seems to explain it:\\...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stored_rows = SparkContext.accumulator(0,[],[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_new_acc_value(rows):\n",
    "    global stored_rows\n",
    "    stored_rows.value.append(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_rows.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@udf(redditSchema)\n",
    "def getRedditComments(reddit, show, sub_reddit, reddit_schema):\n",
    "    content_rows = []\n",
    "    title_split = show.title.split(\":\", 1)\n",
    "    content_title = title_split[0]\n",
    "    subreddit = reddit.subreddit(sub_reddit)\n",
    "    for sm in subreddit.search('\"' + content_title + '\"', sort='top'):\n",
    "        sm.comments.replace_more(limit=None)\n",
    "        row_comments = []\n",
    "        for comment in sm.comments.list():\n",
    "            #row_comments.append(1)\n",
    "            row_comments.append(\n",
    "                (comment.id, comment.body, dt.fromtimestamp(float(comment.created_utc)), comment.score,\n",
    "                 comment.parent_id, comment.link_id))\n",
    "        current_sm = (show.show_id, sm.id, subreddit.display_name, sm.title, sm.selftext,\n",
    "                      dt.fromtimestamp(float(sm.created_utc)), sm.author.name,\n",
    "                      sm.score, sm.spoiler, sm.is_original_content, sm.distinguished, sm.permalink, row_comments)\n",
    "        content_rows.append(current_sm)\n",
    "        # self.log.info('Data extracted from subreddit: {}'.format(sub_reddit))\n",
    "    return content_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['netflix', 'NetflixBestOf']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"netflix  NetflixBestOf\"\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@udf(redditSchema)\n",
    "def getRedditComments(reddit, show, sub_reddit, reddit_schema):\n",
    "    content_rows = []\n",
    "    title_split = show.title.split(\":\", 1)\n",
    "    content_title = title_split[0]\n",
    "    subreddit = reddit.subreddit(sub_reddit)\n",
    "    for sm in subreddit.search('\"' + content_title + '\"', sort='top'):\n",
    "        sm.comments.replace_more(limit=None)\n",
    "        row_comments = []\n",
    "        for comment in sm.comments.list():\n",
    "            #row_comments.append(1)\n",
    "            row_comments.append(\n",
    "                (comment.id, comment.body, dt.fromtimestamp(float(comment.created_utc)), comment.score,\n",
    "                 comment.parent_id, comment.link_id))\n",
    "        current_sm = (show.show_id, sm.id, subreddit.display_name, sm.title, sm.selftext,\n",
    "                      dt.fromtimestamp(float(sm.created_utc)), sm.author.name,\n",
    "                      sm.score, sm.spoiler, sm.is_original_content, sm.distinguished, sm.permalink, row_comments)\n",
    "        content_rows.append(current_sm)\n",
    "        # self.log.info('Data extracted from subreddit: {}'.format(sub_reddit))\n",
    "    return content_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_df = spark.read.parquet('/Users/brayanjules/Projects/personal/data engineer/datasets/netflix_catalog/catalog.parquet',)\n",
    "comments_df = spark.read.parquet('/Users/brayanjules/Projects/personal/data engineer/datasets/reddit_netflix/comments.parquet')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnest_catalog = catalog_df.select(catalog_df.date_added, catalog_df.release_year, catalog_df.title,\n",
    "                                           catalog_df.type, catalog_df.duration, catalog_df.description,\n",
    "                                           catalog_df.director,\n",
    "                                           fc.explode(fc.split(catalog_df.cast, ',')).alias('actor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_added: date (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- actor: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unnest_catalog.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnest_comments = comments_df.where((comments_df.show_title == 'Arthur Christmas') & (comments_df.author == 'default_author')).withColumn('comments',fc.explode(comments_df.comments).alias('comments')).select(comments_df.show_title, comments_df.source, comments_df.title,\n",
    "                                     comments_df.description, comments_df.author,\n",
    "                                    'comments.*')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_title: string (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- comment_id: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- created_utc: timestamp (nullable = true)\n",
      " |-- score: integer (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unnest_comments.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"catalog_temp\")\n",
    "unnest_catalog.createTempView('catalog_temp')\n",
    "spark.catalog.dropTempView(\"comments_temp\")\n",
    "unnest_comments.createTempView('comments_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_result = spark.sql(\n",
    "            'select ct.date_added,ct.release_year,ct.title,ct.type,ct.duration,ct.description,ct.director, '\n",
    "            'COLLECT_LIST(STRUCT(co.body as body,co.author,co.created_utc as created, co.score,null as sentiment, '\n",
    "            'null as description_word, null as source)) as comments, '\n",
    "            'COLLECT_LIST(STRUCT(ct.actor as name)) as actor '\n",
    "            ' from catalog_temp ct inner join comments_temp co on ct.title=co.show_title '\n",
    "            ' group by ct.date_added,ct.release_year,ct.title,ct.type,ct.duration,ct.description,ct.director')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(col=Row(body='jdjmzfvxgdthheyoxdjjmtofrefvotwnfayj', author='default_author', created=datetime.datetime(2020, 3, 28, 16, 54, 20, 790367), score=74, sentiment=None, description_word=None, source=None)),\n",
       " Row(col=Row(body='jdjmzfvxgdthheyoxdjjmtofrefvotwnfayj', author='default_author', created=datetime.datetime(2020, 3, 28, 16, 54, 20, 790367), score=74, sentiment=None, description_word=None, source=None)),\n",
       " Row(col=Row(body='jdjmzfvxgdthheyoxdjjmtofrefvotwnfayj', author='default_author', created=datetime.datetime(2020, 3, 28, 16, 54, 20, 790367), score=74, sentiment=None, description_word=None, source=None)),\n",
       " Row(col=Row(body='jdjmzfvxgdthheyoxdjjmtofrefvotwnfayj', author='default_author', created=datetime.datetime(2020, 3, 28, 16, 54, 20, 790367), score=74, sentiment=None, description_word=None, source=None)),\n",
       " Row(col=Row(body='jdjmzfvxgdthheyoxdjjmtofrefvotwnfayj', author='default_author', created=datetime.datetime(2020, 3, 28, 16, 54, 20, 790367), score=74, sentiment=None, description_word=None, source=None))]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_result.select(fc.explode('comments')).limit(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_added: date (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- comments: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- body: string (nullable = true)\n",
      " |    |    |-- author: string (nullable = true)\n",
      " |    |    |-- created: timestamp (nullable = true)\n",
      " |    |    |-- score: integer (nullable = true)\n",
      " |    |    |-- sentiment: null (nullable = true)\n",
      " |    |    |-- description_word: null (nullable = true)\n",
      " |    |    |-- source: null (nullable = true)\n",
      " |-- actor: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structured_result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_df_schema():\n",
    "        return tp.StructType([tp.StructField('added_date', tp.DateType(), False),\n",
    "                              tp.StructField('release_year', tp.IntegerType(), True),\n",
    "                              tp.StructField('title', tp.StringType(), False),\n",
    "                              tp.StructField('type', tp.StringType(), False),\n",
    "                              tp.StructField('duration', tp.StringType(), True),\n",
    "                              tp.StructField('description', tp.StringType(), True),\n",
    "                              tp.StructField('director', tp.StringType(), True),\n",
    "                              tp.StructField('comments', tp.ArrayType(tp.StructType([\n",
    "                                  tp.StructField('body', tp.StringType(), False),\n",
    "                                  tp.StructField('author', tp.StringType(), False),\n",
    "                                  tp.StructField('created_utc', tp.TimestampType(), False),\n",
    "                                  tp.StructField('score', tp.IntegerType(), False),\n",
    "                                  tp.StructField('sentiment', tp.StringType(), True),\n",
    "                                  tp.StructField('description_word', tp.StringType(), True),\n",
    "                                  tp.StructField('source', tp.StringType(), True)\n",
    "                              ])), False),\n",
    "                              tp.StructField('actors', tp.ArrayType(tp.StructType([\n",
    "                                  tp.StructField('name', tp.StringType(), False)\n",
    "                              ])), True)\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(added_date,DateType,false),StructField(release_year,IntegerType,true),StructField(title,StringType,false),StructField(type,StringType,false),StructField(duration,StringType,true),StructField(description,StringType,true),StructField(director,StringType,true),StructField(comments,ArrayType(StructType(List(StructField(body,StringType,false),StructField(author,StringType,false),StructField(created_utc,TimestampType,false),StructField(score,IntegerType,false),StructField(sentiment,StringType,true),StructField(description_word,StringType,true),StructField(source,StringType,true))),true),false),StructField(actors,ArrayType(StructType(List(StructField(name,StringType,false))),true),true)))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_review_structured = spark.createDataFrame(structured_result.rdd, get_df_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- added_date: date (nullable = false)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- title: string (nullable = false)\n",
      " |-- type: string (nullable = false)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- comments: struct (nullable = false)\n",
      " |    |-- body: string (nullable = false)\n",
      " |    |-- author: string (nullable = false)\n",
      " |    |-- created_utc: timestamp (nullable = false)\n",
      " |    |-- score: integer (nullable = false)\n",
      " |    |-- sentiment: string (nullable = true)\n",
      " |    |-- description_word: string (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |-- actors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- name: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content_review_structured.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1140.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 26 in stage 223.0 failed 1 times, most recent failure: Lost task 26.0 in stage 223.0 (TID 14477, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/session.py\", line 730, in prepare\n    verify_func(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1370, in verify_struct\n    verifier(v)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1368, in verify_struct\n    \"length of fields (%d)\" % (len(obj), len(verifiers))))\nValueError: field comments: Length of object (44000) does not match with length of fields (7)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\n\tat sun.reflect.GeneratedMethodAccessor94.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/session.py\", line 730, in prepare\n    verify_func(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1370, in verify_struct\n    verifier(v)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1368, in verify_struct\n    \"length of fields (%d)\" % (len(obj), len(verifiers))))\nValueError: field comments: Length of object (44000) does not match with length of fields (7)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-4ca53b0ce7b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontent_review_structured\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'comments'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1140.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 26 in stage 223.0 failed 1 times, most recent failure: Lost task 26.0 in stage 223.0 (TID 14477, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/session.py\", line 730, in prepare\n    verify_func(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1370, in verify_struct\n    verifier(v)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1368, in verify_struct\n    \"length of fields (%d)\" % (len(obj), len(verifiers))))\nValueError: field comments: Length of object (44000) does not match with length of fields (7)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\n\tat sun.reflect.GeneratedMethodAccessor94.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/session.py\", line 730, in prepare\n    verify_func(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1370, in verify_struct\n    verifier(v)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1389, in verify\n    verify_value(obj)\n  File \"/opt/anaconda3/lib/python3.7/site-packages/pyspark/sql/types.py\", line 1368, in verify_struct\n    \"length of fields (%d)\" % (len(obj), len(verifiers))))\nValueError: field comments: Length of object (44000) does not match with length of fields (7)\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "content_review_structured.select('comments').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
